{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2d9f9b",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f887521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/yashv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yashv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/yashv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# To perform basic text preprocessing\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# To save files\n",
    "import pickle\n",
    "\n",
    "# To parse 10K and 10Q forms\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# To download 10K and 10Q forms\n",
    "from secedgar import CompanyFilings, FilingType\n",
    "# The following 2 lines are needed if using secedgar \n",
    "# to download files in Jupyter notebook environment\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# For tracking progress in loops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For file path and text manipulation/searching\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1d15d",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69e8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(words: list) -> list:\n",
    "    \"\"\"\n",
    "    Takes a list of words, and returns them after lemmatizing each word.\n",
    "    \n",
    "    INPUTS:\n",
    "        :words (list): List of input words.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        :(list): List of words after lemmatizing each input word.\n",
    "    \"\"\"\n",
    "    return [WordNetLemmatizer().lemmatize(word, 'v') for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27eabf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a string, and returns a list of all words in the string after lemmatization.\n",
    "    \n",
    "    INPUTS:\n",
    "        :text (str): Input text block.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        :(list): List of words after lemmatizing each word in the input text.\n",
    "    \"\"\"\n",
    "    # Splits all words in the text based on whitespace\n",
    "    word_pattern = re.compile('\\w+')\n",
    "    # Returns lemmatized versions of each word found by the above pattern\n",
    "    return lemmatize_words(word_pattern.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8c6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_removal(words):\n",
    "    \"\"\"\n",
    "    Takes a list of words, and returns a list of all words in the list that are not stopwords.\n",
    "    \n",
    "    INPUTS:\n",
    "        :words (list): Input list of words.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        :(list): List of words after removing all the stopwords.\n",
    "    \"\"\"\n",
    "    # English Stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    # Lemmatizing stopwords\n",
    "    lemma_stop_words = lemmatize_words(stop_words)\n",
    "    # Returning only those words that are not in the stopwords list\n",
    "    return [word for word in words if word not in lemma_stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b58212",
   "metadata": {},
   "source": [
    "# Downloading 10Q forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5af486",
   "metadata": {},
   "source": [
    "Downloading the `10Q` forms from the `secedgar` python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0ce179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:14<00:00,  9.92it/s]\n"
     ]
    }
   ],
   "source": [
    "filings_10q = CompanyFilings(\n",
    "    cik_lookup=['fb', 'aapl', 'amzn', 'nflx', 'goog'], \n",
    "    filing_type=FilingType.FILING_10Q, \n",
    "    count=28, \n",
    "    user_agent='Yashveer Singh Sohi (yashveer@seas.upenn.edu)'\n",
    "  )\n",
    "filings_10q.save(\"10Q/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24cdf1",
   "metadata": {},
   "source": [
    "Collecting all the file names, and file paths for the forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9f4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {}\n",
    "filepaths = {}\n",
    "ten_qs_root_dir = \"10Q/\"\n",
    "for ticker in ['fb', 'aapl', 'amzn', 'nflx', 'goog']:\n",
    "    ticker_filenames = os.listdir(ten_qs_root_dir + ticker + \"/10-Q/\")\n",
    "    ticker_filenames.sort()\n",
    "    filenames[ticker] = ticker_filenames\n",
    "    filepaths[ticker] = [ten_qs_root_dir + ticker + \"/10-Q/\" + ticker_filename \n",
    "                       for ticker_filename in ticker_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1dca07",
   "metadata": {},
   "source": [
    "- Reading all the forms\n",
    "- Parsing the content\n",
    "- Lemmatizing the words in the form and removing stop words\n",
    "- Storing these final processed forms\n",
    "- Storing the dates for each form in another dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec68e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " outer:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      " inner loop:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:   5%|▌         | 1/20 [00:04<01:32,  4.87s/it]\u001b[A\n",
      " inner loop:  10%|█         | 2/20 [00:09<01:20,  4.44s/it]\u001b[A\n",
      " inner loop:  15%|█▌        | 3/20 [00:12<01:09,  4.09s/it]\u001b[A\n",
      " inner loop:  20%|██        | 4/20 [00:17<01:09,  4.34s/it]\u001b[A\n",
      " inner loop:  25%|██▌       | 5/20 [00:21<01:06,  4.41s/it]\u001b[A\n",
      " inner loop:  30%|███       | 6/20 [00:25<00:58,  4.16s/it]\u001b[A\n",
      " inner loop:  35%|███▌      | 7/20 [00:29<00:52,  4.04s/it]\u001b[A\n",
      " inner loop:  40%|████      | 8/20 [00:32<00:46,  3.90s/it]\u001b[A\n",
      " inner loop:  45%|████▌     | 9/20 [00:36<00:42,  3.87s/it]\u001b[A\n",
      " inner loop:  50%|█████     | 10/20 [00:42<00:42,  4.29s/it]\u001b[A\n",
      " inner loop:  55%|█████▌    | 11/20 [00:46<00:39,  4.37s/it]\u001b[A\n",
      " inner loop:  60%|██████    | 12/20 [00:50<00:35,  4.38s/it]\u001b[A\n",
      " inner loop:  65%|██████▌   | 13/20 [00:56<00:33,  4.75s/it]\u001b[A\n",
      " inner loop:  70%|███████   | 14/20 [01:02<00:30,  5.07s/it]\u001b[A\n",
      " inner loop:  75%|███████▌  | 15/20 [01:08<00:26,  5.32s/it]\u001b[A\n",
      " inner loop:  80%|████████  | 16/20 [01:15<00:23,  5.90s/it]\u001b[A\n",
      " inner loop:  85%|████████▌ | 17/20 [01:23<00:19,  6.54s/it]\u001b[A\n",
      " inner loop:  90%|█████████ | 18/20 [01:29<00:12,  6.26s/it]\u001b[A\n",
      " inner loop:  95%|█████████▌| 19/20 [01:35<00:06,  6.24s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 20/20 [01:41<00:00,  5.08s/it]\u001b[A\n",
      " outer:  20%|██        | 1/5 [01:41<06:46, 101.60s/it]\n",
      " inner loop:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:   5%|▌         | 1/20 [00:07<02:21,  7.44s/it]\u001b[A\n",
      " inner loop:  10%|█         | 2/20 [00:13<02:03,  6.89s/it]\u001b[A\n",
      " inner loop:  15%|█▌        | 3/20 [00:21<01:59,  7.00s/it]\u001b[A\n",
      " inner loop:  20%|██        | 4/20 [00:28<01:52,  7.03s/it]\u001b[A\n",
      " inner loop:  25%|██▌       | 5/20 [00:34<01:41,  6.78s/it]\u001b[A\n",
      " inner loop:  30%|███       | 6/20 [00:41<01:36,  6.87s/it]\u001b[A\n",
      " inner loop:  35%|███▌      | 7/20 [00:48<01:29,  6.91s/it]\u001b[A\n",
      " inner loop:  40%|████      | 8/20 [03:50<12:30, 62.50s/it]\u001b[A\n",
      " inner loop:  45%|████▌     | 9/20 [03:57<08:16, 45.16s/it]\u001b[A\n",
      " inner loop:  50%|█████     | 10/20 [04:03<05:32, 33.28s/it]\u001b[A\n",
      " inner loop:  55%|█████▌    | 11/20 [04:09<03:44, 24.99s/it]\u001b[A\n",
      " inner loop:  60%|██████    | 12/20 [04:16<02:34, 19.30s/it]\u001b[A\n",
      " inner loop:  65%|██████▌   | 13/20 [04:22<01:47, 15.35s/it]\u001b[A\n",
      " inner loop:  70%|███████   | 14/20 [04:28<01:15, 12.53s/it]\u001b[A\n",
      " inner loop:  75%|███████▌  | 15/20 [04:32<00:50, 10.01s/it]\u001b[A\n",
      " inner loop:  80%|████████  | 16/20 [04:37<00:33,  8.48s/it]\u001b[A\n",
      " inner loop:  85%|████████▌ | 17/20 [04:43<00:23,  7.76s/it]\u001b[A\n",
      " inner loop:  90%|█████████ | 18/20 [04:51<00:15,  7.81s/it]\u001b[A\n",
      " inner loop:  95%|█████████▌| 19/20 [04:58<00:07,  7.39s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 20/20 [05:05<00:00, 15.28s/it]\u001b[A\n",
      " outer:  40%|████      | 2/5 [06:47<11:04, 221.58s/it]\n",
      " inner loop:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:   5%|▌         | 1/20 [00:03<01:06,  3.52s/it]\u001b[A\n",
      " inner loop:  10%|█         | 2/20 [00:06<01:02,  3.47s/it]\u001b[A\n",
      " inner loop:  15%|█▌        | 3/20 [00:10<00:59,  3.53s/it]\u001b[A/opt/anaconda3/envs/stock/lib/python3.8/site-packages/bs4/builder/_htmlparser.py:102: UserWarning: expected name token at '<![@n/ow ^rxwf;m!;cc'\n",
      "  warnings.warn(msg)\n",
      "\n",
      " inner loop:  20%|██        | 4/20 [00:14<00:59,  3.70s/it]\u001b[A\n",
      " inner loop:  25%|██▌       | 5/20 [00:18<00:59,  3.97s/it]\u001b[A\n",
      " inner loop:  30%|███       | 6/20 [00:22<00:55,  3.93s/it]\u001b[A\n",
      " inner loop:  35%|███▌      | 7/20 [00:27<00:54,  4.21s/it]\u001b[A\n",
      " inner loop:  40%|████      | 8/20 [00:32<00:54,  4.57s/it]\u001b[A\n",
      " inner loop:  45%|████▌     | 9/20 [00:37<00:51,  4.68s/it]\u001b[A\n",
      " inner loop:  50%|█████     | 10/20 [00:43<00:49,  4.94s/it]\u001b[A\n",
      " inner loop:  55%|█████▌    | 11/20 [00:49<00:47,  5.24s/it]\u001b[A\n",
      " inner loop:  60%|██████    | 12/20 [00:54<00:41,  5.13s/it]\u001b[A\n",
      " inner loop:  65%|██████▌   | 13/20 [00:59<00:36,  5.17s/it]\u001b[A\n",
      " inner loop:  70%|███████   | 14/20 [01:03<00:28,  4.78s/it]\u001b[A\n",
      " inner loop:  75%|███████▌  | 15/20 [01:07<00:23,  4.68s/it]\u001b[A\n",
      " inner loop:  80%|████████  | 16/20 [01:14<00:20,  5.15s/it]\u001b[A\n",
      " inner loop:  85%|████████▌ | 17/20 [01:19<00:15,  5.33s/it]\u001b[A\n",
      " inner loop:  90%|█████████ | 18/20 [01:25<00:10,  5.43s/it]\u001b[A\n",
      " inner loop:  95%|█████████▌| 19/20 [01:32<00:05,  5.95s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 20/20 [01:39<00:00,  4.96s/it]\u001b[A\n",
      " outer:  60%|██████    | 3/5 [08:26<05:31, 165.66s/it]\n",
      " inner loop:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:   5%|▌         | 1/20 [00:03<01:08,  3.59s/it]\u001b[A\n",
      " inner loop:  10%|█         | 2/20 [00:07<01:10,  3.94s/it]\u001b[A\n",
      " inner loop:  15%|█▌        | 3/20 [00:10<01:01,  3.60s/it]\u001b[A\n",
      " inner loop:  20%|██        | 4/20 [00:14<00:59,  3.71s/it]\u001b[A\n",
      " inner loop:  25%|██▌       | 5/20 [00:18<00:57,  3.81s/it]\u001b[A\n",
      " inner loop:  30%|███       | 6/20 [00:23<00:55,  3.93s/it]\u001b[A\n",
      " inner loop:  35%|███▌      | 7/20 [00:27<00:53,  4.14s/it]\u001b[A\n",
      " inner loop:  40%|████      | 8/20 [00:30<00:46,  3.84s/it]\u001b[A\n",
      " inner loop:  45%|████▌     | 9/20 [00:35<00:44,  4.01s/it]\u001b[A\n",
      " inner loop:  50%|█████     | 10/20 [00:39<00:40,  4.06s/it]\u001b[A\n",
      " inner loop:  55%|█████▌    | 11/20 [00:43<00:37,  4.16s/it]\u001b[A\n",
      " inner loop:  60%|██████    | 12/20 [00:49<00:36,  4.52s/it]\u001b[A\n",
      " inner loop:  65%|██████▌   | 13/20 [00:52<00:30,  4.29s/it]\u001b[A\n",
      " inner loop:  70%|███████   | 14/20 [00:56<00:24,  4.04s/it]\u001b[A\n",
      " inner loop:  75%|███████▌  | 15/20 [01:02<00:22,  4.59s/it]\u001b[A\n",
      " inner loop:  80%|████████  | 16/20 [01:07<00:19,  4.89s/it]\u001b[A\n",
      " inner loop:  85%|████████▌ | 17/20 [01:12<00:14,  4.80s/it]\u001b[A\n",
      " inner loop:  90%|█████████ | 18/20 [01:17<00:09,  4.86s/it]\u001b[A\n",
      " inner loop:  95%|█████████▌| 19/20 [01:22<00:05,  5.10s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 20/20 [01:26<00:00,  4.32s/it]\u001b[A\n",
      " outer:  80%|████████  | 4/5 [09:52<02:14, 134.36s/it]\n",
      " inner loop:   0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:   5%|▌         | 1/19 [00:09<02:42,  9.06s/it]\u001b[A\n",
      " inner loop:  11%|█         | 2/19 [00:18<02:36,  9.23s/it]\u001b[A\n",
      " inner loop:  16%|█▌        | 3/19 [00:28<02:32,  9.56s/it]\u001b[A\n",
      " inner loop:  21%|██        | 4/19 [00:38<02:29,  9.97s/it]\u001b[A\n",
      " inner loop:  26%|██▋       | 5/19 [00:47<02:11,  9.38s/it]\u001b[A\n",
      " inner loop:  32%|███▏      | 6/19 [00:55<01:58,  9.14s/it]\u001b[A\n",
      " inner loop:  37%|███▋      | 7/19 [01:05<01:50,  9.19s/it]\u001b[A\n",
      " inner loop:  42%|████▏     | 8/19 [01:13<01:37,  8.89s/it]\u001b[A/opt/anaconda3/envs/stock/lib/python3.8/site-packages/bs4/builder/_htmlparser.py:102: UserWarning: expected name token at '<![\\nm)y\"e-$if_ &h@1^'\n",
      "  warnings.warn(msg)\n",
      "\n",
      " inner loop:  47%|████▋     | 9/19 [01:19<01:20,  8.03s/it]\u001b[A\n",
      " inner loop:  53%|█████▎    | 10/19 [01:29<01:17,  8.63s/it]\u001b[A\n",
      " inner loop:  58%|█████▊    | 11/19 [01:37<01:08,  8.52s/it]\u001b[A\n",
      " inner loop:  63%|██████▎   | 12/19 [01:47<01:01,  8.78s/it]\u001b[A\n",
      " inner loop:  68%|██████▊   | 13/19 [01:56<00:52,  8.77s/it]\u001b[A\n",
      " inner loop:  74%|███████▎  | 14/19 [02:03<00:42,  8.43s/it]\u001b[A\n",
      " inner loop:  79%|███████▉  | 15/19 [02:15<00:38,  9.51s/it]\u001b[A\n",
      " inner loop:  84%|████████▍ | 16/19 [02:26<00:30, 10.06s/it]\u001b[A\n",
      " inner loop:  89%|████████▉ | 17/19 [02:35<00:19,  9.56s/it]\u001b[A\n",
      " inner loop:  95%|█████████▍| 18/19 [02:46<00:09,  9.88s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 19/19 [02:57<00:00,  9.33s/it]\u001b[A\n",
      " outer: 100%|██████████| 5/5 [12:49<00:00, 153.99s/it]\n"
     ]
    }
   ],
   "source": [
    "ten_q_forms = {}\n",
    "ten_q_forms_dates = {}\n",
    "\n",
    "date_errors = []\n",
    "content_errors = []\n",
    "for ticker, filepath in tqdm(filepaths.items(), total=len(filepaths), desc=\" outer\", position=0):\n",
    "    for path in tqdm(filepath, total=len(filepath), desc=\" inner loop\", position=1, leave=True):\n",
    "        with open(path, \"r\") as f:\n",
    "            form_content = f.read()\n",
    "        try:\n",
    "            m = re.search(pattern=\"FILED AS OF DATE\", string=form_content)\n",
    "            date = \"\".join([s for s in form_content[m.end():m.end()+20] if s.isnumeric()])\n",
    "            date_errors.append(\"NA\")\n",
    "        except:\n",
    "            date = \"NA\"\n",
    "            date_errors.append(path)\n",
    "        \n",
    "        try:\n",
    "            form_text = BeautifulSoup(form_content.lower(), 'html.parser').get_text()\n",
    "            form_tokens = lemmatize_text(form_text)\n",
    "            form_tokens_clean = stop_words_removal(form_tokens)\n",
    "            content_errors.append(\"NA\")\n",
    "        except:\n",
    "            form_tokens_clean = \"NA\"\n",
    "            content_errors.append(path)\n",
    "\n",
    "        if ten_q_forms.get(ticker) == None:\n",
    "            ten_q_forms[ticker] = [form_tokens_clean]\n",
    "            ten_q_forms_dates[ticker] = [date]\n",
    "        else:\n",
    "            ten_q_forms[ticker].append(form_tokens_clean)\n",
    "            ten_q_forms_dates[ticker].append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af05d2",
   "metadata": {},
   "source": [
    "Sanity checks\n",
    "- If the date for any form was not parsed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aede3b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d for d in date_errors if d!=\"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52620124",
   "metadata": {},
   "source": [
    "- If the content for any form was not parsed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc61763e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10Q/amzn/10-Q/0001018724-16-000286.txt',\n",
       " '10Q/goog/10-Q/0001652044-18-000027.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in content_errors if c != \"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4e0c9",
   "metadata": {},
   "source": [
    "Sample structure of how the 10Q form's dates are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863df412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fb': ['20150731',\n",
       "  '20151105',\n",
       "  '20160428',\n",
       "  '20160728',\n",
       "  '20161103',\n",
       "  '20170504',\n",
       "  '20170727',\n",
       "  '20171102',\n",
       "  '20180426',\n",
       "  '20180726',\n",
       "  '20181031',\n",
       "  '20190425',\n",
       "  '20190725',\n",
       "  '20191031',\n",
       "  '20200430',\n",
       "  '20200731',\n",
       "  '20201030',\n",
       "  '20210429',\n",
       "  '20210729',\n",
       "  '20211026'],\n",
       " 'aapl': ['20170802',\n",
       "  '20180202',\n",
       "  '20180502',\n",
       "  '20180801',\n",
       "  '20190130',\n",
       "  '20190501',\n",
       "  '20190731',\n",
       "  '20200129',\n",
       "  '20200501',\n",
       "  '20200731',\n",
       "  '20210128',\n",
       "  '20210429',\n",
       "  '20210728',\n",
       "  '20150428',\n",
       "  '20150722',\n",
       "  '20160127',\n",
       "  '20160427',\n",
       "  '20160727',\n",
       "  '20170201',\n",
       "  '20170503'],\n",
       " 'amzn': ['20150724',\n",
       "  '20151023',\n",
       "  '20160429',\n",
       "  '20160729',\n",
       "  '20161028',\n",
       "  '20170428',\n",
       "  '20170728',\n",
       "  '20171027',\n",
       "  '20180427',\n",
       "  '20180727',\n",
       "  '20181026',\n",
       "  '20190426',\n",
       "  '20190726',\n",
       "  '20191025',\n",
       "  '20200501',\n",
       "  '20200731',\n",
       "  '20201030',\n",
       "  '20210430',\n",
       "  '20210730',\n",
       "  '20211029'],\n",
       " 'nflx': ['20150717',\n",
       "  '20151016',\n",
       "  '20160420',\n",
       "  '20160719',\n",
       "  '20161020',\n",
       "  '20170719',\n",
       "  '20171018',\n",
       "  '20180418',\n",
       "  '20180718',\n",
       "  '20181018',\n",
       "  '20190418',\n",
       "  '20190719',\n",
       "  '20191018',\n",
       "  '20200421',\n",
       "  '20200720',\n",
       "  '20201022',\n",
       "  '20210422',\n",
       "  '20210722',\n",
       "  '20211021',\n",
       "  '20170420'],\n",
       " 'goog': ['20151029',\n",
       "  '20160503',\n",
       "  '20160804',\n",
       "  '20161103',\n",
       "  '20170502',\n",
       "  '20170725',\n",
       "  '20171027',\n",
       "  '20180424',\n",
       "  '20180724',\n",
       "  '20181026',\n",
       "  '20190430',\n",
       "  '20190726',\n",
       "  '20191029',\n",
       "  '20200429',\n",
       "  '20200731',\n",
       "  '20201030',\n",
       "  '20210428',\n",
       "  '20210728',\n",
       "  '20211027']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_q_forms_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b58a8f",
   "metadata": {},
   "source": [
    "Saving the `ten_q_forms` dictionary, and then as a sanity check, reloading it and comparing if it is the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afc2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('ten_q_forms.pickle', 'wb') as handle:\n",
    "    pickle.dump(ten_q_forms, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ten_q_forms.pickle', 'rb') as handle:\n",
    "    ten_q_forms_loaded = pickle.load(handle)\n",
    "    \n",
    "print(ten_q_forms_loaded == ten_q_forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b53fe3",
   "metadata": {},
   "source": [
    "Saving the `ten_q_forms_dates` dictionary, and then as a sanity check, reloading it and comparing if it is the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88fcdaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('ten_q_forms_dates.pickle', 'wb') as handle:\n",
    "    pickle.dump(ten_q_forms_dates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ten_q_forms_dates.pickle', 'rb') as handle:\n",
    "    ten_q_forms_dates_loaded = pickle.load(handle)\n",
    "    \n",
    "print(ten_q_forms_dates_loaded == ten_q_forms_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63235033",
   "metadata": {},
   "source": [
    "# Downloading 10K forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a4375",
   "metadata": {},
   "source": [
    "Downloading the `10K` forms from the `secedgar` python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68ba1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:04,  9.93it/s]                        \n"
     ]
    }
   ],
   "source": [
    "filings_10k = CompanyFilings(\n",
    "    cik_lookup=['fb', 'aapl', 'amzn', 'nflx', 'goog'], \n",
    "    filing_type=FilingType.FILING_10K, \n",
    "    count=7, \n",
    "    user_agent='Yashveer Singh Sohi (yashveer@seas.upenn.edu)'\n",
    "  )\n",
    "filings_10k.save(\"10K/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600109b",
   "metadata": {},
   "source": [
    "Collecting all the file names, and file paths for the forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a044a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {}\n",
    "filepaths = {}\n",
    "ten_ks_root_dir = \"10K/\"\n",
    "for ticker in ['fb', 'aapl', 'amzn', 'nflx', 'goog']:\n",
    "    ticker_filenames = os.listdir(ten_ks_root_dir + ticker + \"/10-K/\")\n",
    "    ticker_filenames.sort()\n",
    "    filenames[ticker] = ticker_filenames\n",
    "    filepaths[ticker] = [ten_ks_root_dir + ticker + \"/10-K/\" + ticker_filename \n",
    "                       for ticker_filename in ticker_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb3dd4",
   "metadata": {},
   "source": [
    "- Reading all the forms\n",
    "- Parsing the content\n",
    "- Lemmatizing the words in the form and removing stop words\n",
    "- Storing these final processed forms\n",
    "- Storing the dates for each form in another dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5673a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " outer:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      " inner loop:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:  14%|█▍        | 1/7 [00:11<01:07, 11.18s/it]\u001b[A\n",
      " inner loop:  29%|██▊       | 2/7 [00:11<00:24,  4.86s/it]\u001b[A\n",
      " inner loop:  43%|████▎     | 3/7 [00:22<00:30,  7.67s/it]\u001b[A\n",
      " inner loop:  57%|█████▋    | 4/7 [00:32<00:26,  8.69s/it]\u001b[A\n",
      " inner loop:  71%|███████▏  | 5/7 [00:44<00:19,  9.59s/it]\u001b[A\n",
      " inner loop:  86%|████████▌ | 6/7 [00:55<00:10, 10.09s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 7/7 [01:07<00:00,  9.63s/it]\u001b[A\n",
      " outer:  20%|██        | 1/5 [01:07<04:29, 67.42s/it]\n",
      " inner loop:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:  14%|█▍        | 1/7 [00:13<01:19, 13.25s/it]\u001b[A\n",
      " inner loop:  29%|██▊       | 2/7 [00:25<01:02, 12.56s/it]\u001b[A\n",
      " inner loop:  43%|████▎     | 3/7 [00:45<01:03, 15.98s/it]\u001b[A\n",
      " inner loop:  57%|█████▋    | 4/7 [01:00<00:47, 15.69s/it]\u001b[A\n",
      " inner loop:  71%|███████▏  | 5/7 [01:06<00:23, 11.98s/it]\u001b[A\n",
      " inner loop:  86%|████████▌ | 6/7 [01:30<00:16, 16.11s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 7/7 [01:48<00:00, 15.44s/it]\u001b[A\n",
      " outer:  40%|████      | 2/5 [02:55<04:34, 91.34s/it]\n",
      " inner loop:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:  14%|█▍        | 1/7 [00:29<02:59, 29.91s/it]\u001b[A\n",
      " inner loop:  29%|██▊       | 2/7 [01:10<03:00, 36.12s/it]\u001b[A\n",
      " inner loop:  43%|████▎     | 3/7 [02:00<02:49, 42.49s/it]\u001b[A\n",
      " inner loop:  57%|█████▋    | 4/7 [02:31<01:53, 37.92s/it]\u001b[A\n",
      " inner loop:  71%|███████▏  | 5/7 [03:21<01:24, 42.41s/it]\u001b[A\n",
      " inner loop:  86%|████████▌ | 6/7 [03:39<00:33, 34.00s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 7/7 [04:10<00:00, 35.72s/it]\u001b[A\n",
      " outer:  60%|██████    | 3/5 [07:05<05:27, 163.80s/it]\n",
      " inner loop:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:  14%|█▍        | 1/7 [00:25<02:31, 25.21s/it]\u001b[A\n",
      " inner loop:  29%|██▊       | 2/7 [00:42<01:43, 20.73s/it]\u001b[A\n",
      " inner loop:  43%|████▎     | 3/7 [00:42<00:45, 11.33s/it]\u001b[A\n",
      " inner loop:  57%|█████▋    | 4/7 [00:57<00:38, 12.74s/it]\u001b[A\n",
      " inner loop:  71%|███████▏  | 5/7 [01:12<00:26, 13.43s/it]\u001b[A\n",
      " inner loop:  86%|████████▌ | 6/7 [01:27<00:14, 14.02s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 7/7 [01:42<00:00, 14.71s/it]\u001b[A\n",
      " outer:  80%|████████  | 4/5 [08:48<02:19, 139.79s/it]\n",
      " inner loop:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " inner loop:  14%|█▍        | 1/7 [00:00<00:02,  2.27it/s]\u001b[A\n",
      " inner loop:  43%|████▎     | 3/7 [00:31<00:46, 11.56s/it]\u001b[A\n",
      " inner loop:  57%|█████▋    | 4/7 [00:50<00:43, 14.36s/it]\u001b[A\n",
      " inner loop:  71%|███████▏  | 5/7 [01:21<00:39, 19.72s/it]\u001b[A\n",
      " inner loop:  86%|████████▌ | 6/7 [01:41<00:19, 19.80s/it]\u001b[A\n",
      " inner loop: 100%|██████████| 7/7 [02:00<00:00, 17.19s/it]\u001b[A\n",
      " outer: 100%|██████████| 5/5 [10:48<00:00, 129.76s/it]\n"
     ]
    }
   ],
   "source": [
    "ten_k_forms = {}\n",
    "ten_k_forms_dates = {}\n",
    "\n",
    "date_errors = []\n",
    "content_errors = []\n",
    "for ticker, filepath in tqdm(filepaths.items(), total=len(filepaths), desc=\" outer\", position=0):\n",
    "    for path in tqdm(filepath, total=len(filepath), desc=\" inner loop\", position=1, leave=True):\n",
    "        with open(path, \"r\") as f:\n",
    "            form_content = f.read()\n",
    "        try:\n",
    "            m = re.search(pattern=\"FILED AS OF DATE\", string=form_content)\n",
    "            date = \"\".join([s for s in form_content[m.end():m.end()+20] if s.isnumeric()])\n",
    "            date_errors.append(\"NA\")\n",
    "        except:\n",
    "            date = \"NA\"\n",
    "            date_errors.append(path)\n",
    "        \n",
    "        try:\n",
    "            form_text = BeautifulSoup(form_content.lower(), 'html.parser').get_text()\n",
    "            form_tokens = lemmatize_text(form_text)\n",
    "            form_tokens_clean = stop_words_removal(form_tokens)\n",
    "            content_errors.append(\"NA\")\n",
    "        except:\n",
    "            form_tokens_clean = \"NA\"\n",
    "            content_errors.append(path)\n",
    "\n",
    "        if ten_k_forms.get(ticker) == None:\n",
    "            ten_k_forms[ticker] = [form_tokens_clean]\n",
    "            ten_k_forms_dates[ticker] = [date]\n",
    "        else:\n",
    "            ten_k_forms[ticker].append(form_tokens_clean)\n",
    "            ten_k_forms_dates[ticker].append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6b9e1",
   "metadata": {},
   "source": [
    "Sanity checks\n",
    "- If the date for any form was not parsed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3e26a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d for d in date_errors if d!=\"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8144dc",
   "metadata": {},
   "source": [
    "- If the content for any form was not parsed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c014d519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in content_errors if c != \"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3c63e",
   "metadata": {},
   "source": [
    "Sample structure of how the 10K form's dates are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf6d3328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fb': ['20160128',\n",
       "  '20160427',\n",
       "  '20170203',\n",
       "  '20180201',\n",
       "  '20190131',\n",
       "  '20200130',\n",
       "  '20210128'],\n",
       " 'aapl': ['20171103',\n",
       "  '20181105',\n",
       "  '20191031',\n",
       "  '20201030',\n",
       "  '20211029',\n",
       "  '20151028',\n",
       "  '20161026'],\n",
       " 'amzn': ['20150130',\n",
       "  '20160129',\n",
       "  '20170210',\n",
       "  '20180202',\n",
       "  '20190201',\n",
       "  '20200131',\n",
       "  '20210203'],\n",
       " 'nflx': ['20180129',\n",
       "  '20190129',\n",
       "  '20190208',\n",
       "  '20200129',\n",
       "  '20210128',\n",
       "  '20170127',\n",
       "  '20180205'],\n",
       " 'goog': ['20160329',\n",
       "  '20190206',\n",
       "  '20170203',\n",
       "  '20180206',\n",
       "  '20190205',\n",
       "  '20200204',\n",
       "  '20210203']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_k_forms_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00828329",
   "metadata": {},
   "source": [
    "Saving the `ten_k_forms` dictionary, and then as a sanity check, reloading it and comparing if it is the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0928553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('ten_k_forms.pickle', 'wb') as handle:\n",
    "    pickle.dump(ten_k_forms, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ten_k_forms.pickle', 'rb') as handle:\n",
    "    ten_k_forms_loaded = pickle.load(handle)\n",
    "    \n",
    "print(ten_k_forms_loaded == ten_k_forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4929f36",
   "metadata": {},
   "source": [
    "Saving the `ten_k_forms_dates` dictionary, and then as a sanity check, reloading it and comparing if it is the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1dbec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('ten_k_forms_dates.pickle', 'wb') as handle:\n",
    "    pickle.dump(ten_k_forms_dates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ten_k_forms_dates.pickle', 'rb') as handle:\n",
    "    ten_k_forms_dates_loaded = pickle.load(handle)\n",
    "    \n",
    "print(ten_k_forms_dates_loaded == ten_k_forms_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
